
### AUTOMATIC TRAINING DATA GENERATION FOR NEURAL QA MODEL ###


The final output file has each row of the form: 
['Property', 'Label ', 'Range', 'Fuzzy Score', 'Comment about expr', 'URI', 'Number of Occurrences', 'MVE', 'Optimal Expression', 'SPARQL Query Template', 'Generator Query\r\n']

# STEP 1 - Get properties from web page #
Command: python get_properties.py --url <WEBPAGE URL> > temp.csv
- --url argument is the webpage from where property metadata is to scraped

# STEP 2 - Get number of occurrences and URI #
Store only the rows of required namespace properties

# STEP 3 - Integrate STEP 2 values with their corresponding property metadata row in temp.csv #
Command: python integrate.py temp.csv
Output file: manual-annotation-updated-v2.csv (change it in the file if needed)
- Change the namespace to the required (it is 'ontology' right now) 

# STEP 4 - MVE generation #
Command: python decision_tree.py data/manual-annotation-updated-v2.csv
Output file: GS_with_mve.csv

# STEP 5 - SPARQL Query Template and Generator Query generation #
Command: python sparql_generator.py GS_with_mve.csv

# STEP 6 - Follow the original data generation and training steps (readme of master branch)

### COMPOSITIONALITY EXPERIMENT: ###

# STEP 1 - Create template annotations (all a[i]'s)
Command: python range_place.py data/GS-v3.csv > data/annotations_compositions_combined.csv


# STEP 2 - Create composite templates (a[i]â—‹b true for all i <= sizeof list 'a')
Command: python composite_template.py data/GS-v3.csv >> data/annotations_compositions_combined.csv

# STEP 3 - Follow the original data generation and training steps (readme of master branch)

# STEP 4 - Choose any 10% templates and their output and shift it to new file (test data), rest of the contents of this file should be split into 90% train and 10% dev using the split_in_train_dev_test.py script.

# STEP 5 - Run the training
Command: sh train.sh <path of directory which contains train, dev and test data>
